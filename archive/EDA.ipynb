{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from openai import OpenAI\n",
    "from eval_veracity_prediction import print_evaluation_results\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../openAI_apikey.json\", \"r\") as fp:\n",
    "    openai_api_key = json.load(fp)[\"openAI_api_key\"]\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and preprocess quantemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/quantemp/test_claims_quantemp.json\", \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "data = pd.DataFrame(data)\n",
    "data = data[[\"query_id\", \"claim\", \"taxonomy_label\", \"doc\",  \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(data, embedding_model, with_taxonomy = False, with_evidence = False, use_openai = False,):\n",
    "    embedded_list = []\n",
    "    label_list = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        sample = data.iloc[idx]\n",
    "        if with_taxonomy == True and with_evidence == True: \n",
    "            sentence = f\"\"\"\n",
    "                        [Claim]: {sample[\"claim\"]}\n",
    "                        [Taxonomy]: {sample[\"taxonomy_label\"]}\n",
    "                        [Evidence]: {sample[\"doc\"]}\n",
    "                        \"\"\"\n",
    "        elif with_taxonomy == True: \n",
    "            sentence = f\"\"\"\n",
    "                        [Claim]: {sample[\"claim\"]}\n",
    "                        [Taxonomy]: {sample[\"taxonomy_label\"]}\n",
    "                        \"\"\"\n",
    "        elif with_evidence == True: \n",
    "            sentence = f\"\"\"\n",
    "                        [Claim]: {sample[\"claim\"]}\n",
    "                        [Evidence]: {sample[\"doc\"]}\n",
    "                        \"\"\"\n",
    "        else:\n",
    "            sentence = f\"\"\"\n",
    "                        [Claim]: {sample[\"claim\"]}\n",
    "                        \"\"\"\n",
    "\n",
    "        sentence = sentence.replace(\"\\n\", \" \")\n",
    "        if use_openai == True: \n",
    "            embedded_claim = client.embeddings.create(input = [sentence], model=\"text-embedding-3-small\", dimensions = 512 ).data[0].embedding\n",
    "        elif use_openai == False:  \n",
    "            embedded_claim = embedding_model.encode(sentence)\n",
    "        label_list.append(sample[\"label\"])\n",
    "        embedded_list.append(np.array(embedded_claim))\n",
    "    \n",
    "    return embedded_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>taxonomy_label</th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The non-partisan Congressional Budget Office ...</td>\n",
       "      <td>statistical</td>\n",
       "      <td>Republican U.S House candidate Roger Williams ...</td>\n",
       "      <td>Conflicting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"More than 50 percent of immigrants from (El S...</td>\n",
       "      <td>statistical</td>\n",
       "      <td>The crisis at the border brought on by thousan...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UK government banned Covid vaccine for childre...</td>\n",
       "      <td>temporal</td>\n",
       "      <td>\"BREAKING: Children in the UK aged 5-11 will n...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"[In 2014-2015] coverage for the rotavirus vac...</td>\n",
       "      <td>statistical</td>\n",
       "      <td>In its annual performance plan the Free State ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In September 2021, the U.K. government announc...</td>\n",
       "      <td>temporal</td>\n",
       "      <td>In September 2021, several news outlets and we...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                              claim taxonomy_label  \\\n",
       "0         0  \"The non-partisan Congressional Budget Office ...    statistical   \n",
       "1         1  \"More than 50 percent of immigrants from (El S...    statistical   \n",
       "2         2  UK government banned Covid vaccine for childre...       temporal   \n",
       "3         3  \"[In 2014-2015] coverage for the rotavirus vac...    statistical   \n",
       "4         4  In September 2021, the U.K. government announc...       temporal   \n",
       "\n",
       "                                                 doc        label  \n",
       "0  Republican U.S House candidate Roger Williams ...  Conflicting  \n",
       "1  The crisis at the border brought on by thousan...         True  \n",
       "2  \"BREAKING: Children in the UK aged 5-11 will n...        False  \n",
       "3  In its annual performance plan the Free State ...        False  \n",
       "4  In September 2021, several news outlets and we...         True  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2495/2495 [14:08<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded list shape: (2495, 512)\n"
     ]
    }
   ],
   "source": [
    "embedded_list, label_list = generate_embeddings(data, embedding_model, with_taxonomy=False, with_evidence=False, use_openai=True)\n",
    "# embedded_list, label_list = np.load(\"../data/openAI_embedding/small_taxonomy.npy\"), np.load(\"../data/openAI_embedding/label_list.npy\")\n",
    "taxonomy_list = data[\"taxonomy_label\"].to_list()\n",
    "embedded_list = np.array(embedded_list)\n",
    "print(f\"Embedded list shape: {embedded_list.shape}\")\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "tnse_embeddings = tsne.fit_transform(embedded_list)\n",
    "pca_embeddings = pca.fit_transform(embedded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/openAI_embedding/small_claim.npy\", embedded_list)\n",
    "# np.save(\"../data/openAI_embedding/label_list.npy\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_results(label_list, taxonomy_list, reduced_embeddings, embedding_type = \"t-SNE\"):\n",
    "\n",
    "#     class_names = [\"True\", \"False\", \"Conflicting\"]  # Unique class names in the same order\n",
    "\n",
    "#     # Define a color mapping for each class\n",
    "#     color_mapping = {\"True\": \"green\", \"False\": \"red\", \"Conflicting\": \"blue\"}\n",
    "\n",
    "#     # Create the plot\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     for taxonomy_name in set(taxonomy_list):\n",
    "\n",
    "#         # Plot each class with its respective color\n",
    "#         for class_name in class_names:\n",
    "#             indices = [i for i, label in enumerate(label_list) if (label == class_name and taxonomy_list[i] == taxonomy_name)]\n",
    "#             plt.scatter(\n",
    "#                 [reduced_embeddings[i, 0] for i in indices], \n",
    "#                 [reduced_embeddings[i, 1] for i in indices], \n",
    "#                 label=class_name,\n",
    "#                 color=color_mapping[class_name]\n",
    "#             )\n",
    "\n",
    "#         # Add title and labels\n",
    "#         plt.title(f\"Sentence Embeddings Visualized Using {embedding_type}\")\n",
    "#         plt.xlabel(f\"{embedding_type} Dimension 1\")\n",
    "#         plt.ylabel(f\"{embedding_type} Dimension 2\")\n",
    "#         plt.legend()\n",
    "#         plt.savefig(f\"{embedding_type}_{taxonomy_name}.png\")\n",
    "#         plt.grid(True)\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(label_list, taxonomy_list, reduced_embeddings, embedding_type=\"t-SNE\", plot_type=\"both\"):\n",
    "    \"\"\"\n",
    "    Visualize embeddings with color for class_name and/or marker for taxonomy_name.\n",
    "    \n",
    "    Parameters:\n",
    "    - label_list: List of class names corresponding to embeddings.\n",
    "    - taxonomy_list: List of taxonomy names corresponding to embeddings.\n",
    "    - reduced_embeddings: 2D numpy array or list of reduced embeddings (x, y).\n",
    "    - embedding_type: String indicating embedding method (e.g., \"t-SNE\").\n",
    "    - plot_type: String indicating the plot type: \"class\", \"taxonomy\", or \"both\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Define unique class names and taxonomy names\n",
    "    class_names = [\"True\", \"False\", \"Conflicting\"]\n",
    "    taxonomy_names = list(set(taxonomy_list))\n",
    "    \n",
    "    # Define a color mapping for class_name\n",
    "    color_mapping_class = {\"True\": \"green\", \"False\": \"red\", \"Conflicting\": \"blue\"}\n",
    "    marker_mapping_class = {\"True\": \"o\", \"False\": \"x\", \"Conflicting\": \"s\"}\n",
    "    \n",
    "    # Define a color and marker mapping for taxonomy_name\n",
    "    color_mapping_taxonomy = {\n",
    "        name: color for name, color in zip(taxonomy_names, ['red', 'blue', 'green', 'purple'])\n",
    "    }\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    if plot_type == \"class\":\n",
    "        # Plot only by class_name (color-coded)\n",
    "        for class_name in class_names:\n",
    "            indices = [i for i, label in enumerate(label_list) if label == class_name]\n",
    "            plt.scatter(\n",
    "                [reduced_embeddings[i, 0] for i in indices],\n",
    "                [reduced_embeddings[i, 1] for i in indices],\n",
    "                color=color_mapping_class[class_name],\n",
    "                label=class_name,\n",
    "                marker=marker_mapping_class[class_name]\n",
    "            )\n",
    "    \n",
    "    elif plot_type == \"taxonomy\":\n",
    "        # Plot only by taxonomy_name (color-coded and marker-coded)\n",
    "        for taxonomy_name in taxonomy_names:\n",
    "            indices = [i for i, taxonomy in enumerate(taxonomy_list) if taxonomy == taxonomy_name]\n",
    "            plt.scatter(\n",
    "                [reduced_embeddings[i, 0] for i in indices],\n",
    "                [reduced_embeddings[i, 1] for i in indices],\n",
    "                color=color_mapping_taxonomy[taxonomy_name],\n",
    "                label=taxonomy_name\n",
    "            )\n",
    "    \n",
    "    elif plot_type == \"both\":\n",
    "        # Plot by both class_name (color-coded) and taxonomy_name (marker-coded)\n",
    "        for taxonomy_name in taxonomy_names:\n",
    "            for class_name in class_names:\n",
    "                indices = [\n",
    "                    i for i, label in enumerate(label_list) \n",
    "                    if label == class_name and taxonomy_list[i] == taxonomy_name\n",
    "                ]\n",
    "                facecolors = \"none\" if marker_mapping_class[class_name] == \"s\" else color_mapping_taxonomy[taxonomy_name]\n",
    "                plt.scatter(\n",
    "                    [reduced_embeddings[i, 0] for i in indices],\n",
    "                    [reduced_embeddings[i, 1] for i in indices],\n",
    "                    edgecolors=color_mapping_taxonomy[taxonomy_name],\n",
    "                    marker=marker_mapping_class[class_name],\n",
    "                    facecolors=facecolors,\n",
    "                    label=f\"{taxonomy_name} - {class_name}\"\n",
    "                )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid plot_type. Choose from 'class', 'taxonomy', or 'both'.\")\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title(f\"Sentence Embeddings Visualized Using {embedding_type}\")\n",
    "    plt.xlabel(f\"{embedding_type} Dimension 1\")\n",
    "    plt.ylabel(f\"{embedding_type} Dimension 2\")\n",
    "    plt.legend(loc=\"best\", fontsize='small', bbox_to_anchor=(1.05, 1))\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and show the plot\n",
    "    plt.savefig(f\"{embedding_type}_{plot_type}_visualization.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the TSNE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(label_list, taxonomy_list, tnse_embeddings, embedding_type=\"t-SNE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try it with PCA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_981605/2323041346.py:61: UserWarning: You passed a edgecolor/edgecolors ('red') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  plt.scatter(\n",
      "/tmp/ipykernel_981605/2323041346.py:61: UserWarning: You passed a edgecolor/edgecolors ('blue') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  plt.scatter(\n",
      "/tmp/ipykernel_981605/2323041346.py:61: UserWarning: You passed a edgecolor/edgecolors ('green') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  plt.scatter(\n",
      "/tmp/ipykernel_981605/2323041346.py:61: UserWarning: You passed a edgecolor/edgecolors ('purple') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  plt.scatter(\n"
     ]
    }
   ],
   "source": [
    "visualize_results(label_list, taxonomy_list, pca_embeddings, embedding_type=\"PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try training a classifier on top of them without dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = embedded_list, np.array(label_list)\n",
    "# enc = OneHotEncoder(sparse_output = False)\n",
    "# y_transformed = enc.fit_transform(y.reshape(y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train, X_test, y_train, and y_test are: (1996, 512), (499, 512), (1996,), (499,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(embedded_list, y, test_size=0.2)\n",
    "print(f\"Shape of X_train, X_test, y_train, and y_test are: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false     0.6534    0.9394    0.7707       297\n",
      "        true     0.3529    0.0714    0.1188        84\n",
      " conflicting     0.3818    0.1780    0.2428       118\n",
      "\n",
      "    accuracy                         0.6132       499\n",
      "   macro avg     0.4627    0.3963    0.3774       499\n",
      "weighted avg     0.5386    0.6132    0.5361       499\n",
      "\n",
      "[[279   2  16]\n",
      " [ 60   6  18]\n",
      " [ 88   9  21]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfier = RandomForestClassifier()\n",
    "classfier.fit(X_train, y_train)\n",
    "y_pred = classfier.predict(X_test)\n",
    "print_evaluation_results(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false     0.6929    0.8889    0.7788       297\n",
      "        true     0.3704    0.2381    0.2899        84\n",
      " conflicting     0.4219    0.2288    0.2967       118\n",
      "\n",
      "    accuracy                         0.6232       499\n",
      "   macro avg     0.4951    0.4519    0.4551       499\n",
      "weighted avg     0.5745    0.6232    0.5825       499\n",
      "\n",
      "[[264  15  18]\n",
      " [ 45  20  19]\n",
      " [ 72  19  27]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfier = XGBClassifier()\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "classfier.fit(X_train, y_train_encoded)\n",
    "y_pred = classfier.predict(X_test)\n",
    "y_pred_inv = le.inverse_transform(y_pred)\n",
    "print_evaluation_results(y_pred_inv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory analysis of dependency parser. \n",
    "We hypothesize that dependency parsing might be a good candidate to find correlation between sentence complexity and impact of decomposition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "sample = data.iloc[idx]\n",
    "print(sample[\"claim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(str(sample[\"claim\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "displacy.render(doc, style = \"dep\", options = {\"compact\": True, \"distance\": 90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = SequenceTagger.load(\"ner\")  # Loads a pretrained NER model\n",
    "\n",
    "# Create a sentence\n",
    "sentence = Sentence(sample[\"claim\"])\n",
    "\n",
    "# Predict entities (spans)\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# Print detected spans\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(f\"Span: {entity.text}, Label: {entity.tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract latent embeddings of the queries and training data query of different complexities from different layers of the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Replace with the specific LLaMA model you are using\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, output_hidden_states=True)  # Enable hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\"The day the earth stood still.\", \"I am a good boy.\", \"Hello darkness my old friend. I have come to talk to you again\",\n",
    "              ]\n",
    "# Tokenize the batch (pad to the longest sequence and create tensors)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "inputs = tokenizer(input_text, padding=True,  return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():  # No gradient computation required\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract hidden states\n",
    "hidden_states = outputs.hidden_states  # A tuple containing hidden states for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 3, 15, 4096])\n"
     ]
    }
   ],
   "source": [
    "hidden_states = torch.stack(hidden_states)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive_decomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
